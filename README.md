Baseline model
https://www.kaggle.com/code/shivamburnwal/speech-emotion-recognition/notebook

<h2>Dataset</h2>
The Audio Dataset comes from 5 sources
1. Crowd Sourced Emotional Multimodal Actors Dataset (CREMA-D)
2. RAVDESS Emotional speech audio
3. Surrey Audio-Visual Expressed Emotion (SAVEE)
4. Toronto emotional speech set (TESS)
5. Emotional Speech Database (ESD)

The first four datasets are used to train/test the FINs and classification network. The ESD dataset is used to test the generalizability of the FINs.

The time-span of the audio files are from two to five seconds, and the audio data was processed with a sampling rate of 22kHz. 

In total, 12,161 audio files were used in the project.


<h2>Preprocessing</h2>

